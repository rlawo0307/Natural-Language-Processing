{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_IN_PATH = 'C:/jupyter_project/Estimation _Analysis_with_Tensorflow_and_Natural_Language_Processing/data/DATA_IN/'\n",
    "DIR_PATH = 'C:/jupyter_project/Estimation _Analysis_with_Tensorflow_and_Natural_Language_Processing/data/DATA_IN/nsmc/'\n",
    "\n",
    "train_data = pd.read_csv(DATA_IN_PATH+'갓지웅.txt', header=0, delimiter='\\t', quoting=3)\n",
    "test_data = pd.read_csv(DATA_IN_PATH+'test_wong.txt', header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(check, okt, remove_stopwords = False, stop_words = []):\n",
    "    result = []\n",
    "    tmp = re.compile('[^가-힣]+')\n",
    "    res = tmp.sub('', check)\n",
    "    \n",
    "    res = okt.morphs(res, stem=True)\n",
    "    \n",
    "    for w in res:\n",
    "        if w not in stop_words:\n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data_arr):\n",
    "    sim = [['과제', '레포트', '플', '조별', '발표', '독후감', '프로젝트'],\n",
    "           ['난이도', '시험', '중간고사', '기말고사', '중간', '기', '말', '변별', '범위', '셤', '문제', '퀴즈'],\n",
    "           ['출석', '탈주', '출결', '출첵'],\n",
    "           ['수업', '강의', '진도', '과목', '전공', '교양', '내용', '설명', '퀄리티', '학기'],\n",
    "           ['인성', '교수', '인격']]\n",
    "    temp = [[0]*0 for i in range(len(sim))]\n",
    "    key = [[0]*0 for i in range(len(sim))]\n",
    "    tmp = 0\n",
    "    cnt = 0\n",
    "    for i in data_arr:\n",
    "        last = -1\n",
    "        now = -1\n",
    "        for j in i:\n",
    "            for k in sim:\n",
    "                for l in k:\n",
    "                    if j == l:\n",
    "                        cnt+=1\n",
    "                        now = i.index(j, last+1)\n",
    "                        if last != -1:\n",
    "                            for m in sim:\n",
    "                                for n in m:\n",
    "                                    if n == i[last]:\n",
    "                                        tmp = sim.index(m)\n",
    "                            if tmp != sim.index(k):\n",
    "                                storage = tmp\n",
    "                            else:\n",
    "                                storage = sim.index(k)\n",
    "                            while last < now-1:\n",
    "                                temp[storage].append(i[last+1])\n",
    "                                last+=1\n",
    "                    last = now\n",
    "        if cnt != 0:\n",
    "            for m in sim:\n",
    "                for n in m:\n",
    "                    if n == i[now]:\n",
    "                        tmp = sim.index(m)\n",
    "            while(last < len(i)-1):\n",
    "                temp[tmp].append(i[last+1])\n",
    "                last+=1\n",
    "        key[0].append(temp[0])\n",
    "        key[1].append(temp[1])\n",
    "        key[2].append(temp[2])\n",
    "        key[3].append(temp[3])\n",
    "        key[4].append(temp[4])\n",
    "        cnt = 0\n",
    "        temp = [[0]*0 for i in range(len(sim))]        \n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_label(attr, label): #라벨을 6개의 속성에 따라 분리\n",
    "    tmp = []\n",
    "    cnt = 0\n",
    "    for i in label:\n",
    "        if attr == 0:\n",
    "            tmp.append(int(i/10000))\n",
    "        elif attr == 1:\n",
    "            tmp.append(int(i/1000%10))\n",
    "        elif attr == 2:\n",
    "            tmp.append(int(i/100%10))\n",
    "        elif attr == 3:\n",
    "            tmp.append(int(i%100/10))\n",
    "        elif attr == 4:\n",
    "            tmp.append(int(i%10))\n",
    "    return tmp\n",
    "    \n",
    "def cal_len(arr):\n",
    "    max = 0\n",
    "    for i in arr:\n",
    "        if max < len(i):\n",
    "            max = len(i)\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_Tok(key, raw_data, path): #raw_data에서 label값 추출\n",
    "    str = ['과제', '시험', '출석', '수업', '인성']\n",
    "    temp = np.array(raw_data['label'])\n",
    "    last = -1\n",
    "    for i in key:\n",
    "        tmp = key.index(i, last+1)\n",
    "        label_arr = trans_label(tmp, temp)\n",
    "        \n",
    "        #label이 2에 해당하는 데이터와 라벨 없애기\n",
    "        prev = -1\n",
    "        del_label_index = []\n",
    "        for j in label_arr:\n",
    "            if j == 2:\n",
    "                now = label_arr.index(j, prev+1)\n",
    "                del_label_index.append(now)\n",
    "                prev = now\n",
    "        for j in del_label_index:\n",
    "            del label_arr[j-del_label_index.index(j)]\n",
    "            del i[j-del_label_index.index(j)]\n",
    "\n",
    "        DATA = path+\"data_\"+str[tmp]+\".npy\"\n",
    "        LABEL = path+\"label_\"+str[tmp]+\".npy\"\n",
    "        CONFIGS = path+str[tmp]+\"_configs.json\"\n",
    "        \n",
    "        Tok(i, label_arr, DATA, LABEL, CONFIGS)\n",
    "        last = tmp\n",
    "        \n",
    "def Tok(key, label_arr, DATA, LABEL, CONFIGS):\n",
    "    #패딩처리 : 레코드나 블록의 맨 나중에공백이나 의미가 없는 기호를 부가하여 고정 길이로 만드는 것\"\"\"\n",
    "    tok = Tokenizer()\n",
    "    tok.fit_on_texts(key) #입력에 맞게 내부의 word_index를 만듬\n",
    "    seq = tok.texts_to_sequences(key)\n",
    "    maxlen = cal_len(key)\n",
    "    data = pad_sequences(seq, maxlen, padding='post')\n",
    "    \n",
    "    word_vocab = tok.word_index\n",
    "    data_configs = {}\n",
    "    data_configs['vocab'] = word_vocab\n",
    "    data_configs['vocab_size'] = len(word_vocab)+1\n",
    "\n",
    "    np.save(open(DIR_PATH+DATA, 'wb'), data)\n",
    "    np.save(open(DIR_PATH+LABEL, 'wb'), label_arr)\n",
    "    json.dump(data_configs, open(DIR_PATH+CONFIGS, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "stop_words = set(['도','흠','은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'])\n",
    "train_res = []\n",
    "test_res = []\n",
    "\n",
    "for check in train_data ['document']:\n",
    "    if type(check) == str:\n",
    "        train_res.append(preprocessing(check, okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        train_res.append([])\n",
    "        \n",
    "for check in test_data ['document']:\n",
    "    if type(check) == str:\n",
    "        test_res.append(preprocessing(check, okt, remove_stopwords = True, stop_words = stop_words))\n",
    "    else:\n",
    "        test_res.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_key = classify(train_res)\n",
    "test_key = classify(test_res)\n",
    "\n",
    "call_Tok(train_key, train_data, 'train_')\n",
    "call_Tok(test_key, test_data, 'test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
